<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>laue_net_part1</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>

<style type="text/css">
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
	color: black;
	background: none;
	text-shadow: 0 1px white;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
	text-shadow: none;
	background: #b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
	text-shadow: none;
	background: #b3d4fc;
}

@media print {
	code[class*="language-"],
	pre[class*="language-"] {
		text-shadow: none;
	}
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #f5f2f0;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: slategray;
}

.token.punctuation {
	color: #999;
}

.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
	color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
	color: #a67f59;
	background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
	color: #07a;
}

.token.function {
	color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
	color: #e90;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}
</style>


</head>

<body>

<h2 id="toc_0">Laue net</h2>

<h3 id="toc_1">Table of Contents</h3>

<ol>
<li><a href="#gather">Gather data from precognition logs</a></li>
<li><a href="#verify">Verify data in the logs</a></li>
<li><a href="#indexa">Running indexmajig</a></li>
</ol>

<p><a name="gather"></a></p>

<h2 id="toc_2">Gather data from precognition logs</h2>

<div><pre><code class="language-python">%matplotlib inline
# this notebook is the start of a neural network routine
# that uses Bragg spot locations and intensity and wavelength spectrum analysis
# to assign a Bragg spots wavelength

# we begin with data taken from precognition on
# a well diffracting protein crystal 

# this is based on the serial-millisecond methof of crystallograhy
# hence each frame represents a snapshot
import sys,os
import glob,re
import numpy as np
import pandas
</code></pre></div>

<div><pre><code class="language-python"># We start with the precognition log files 
# after it was used to successfully index and integrate
# several patterns

# the goal here is to get the relevant information from the logs into
# e.g. (orientation matrix, filename) tuples

log_hits = open(&quot;process_all.log&quot;, &quot;r&quot;).read()
log_matrix = open(&quot;apply_all_3sig.log&quot;,&quot;r&quot;).read()
</code></pre></div>

<div><pre><code class="language-python">hit_names = re.findall(&quot;run[0-9]{4}_[0-9]{5}.mccd&quot;, log_hits)</code></pre></div>

<div><pre><code class="language-python">index_info = re.findall(&quot;@run[0-9]{4}_[0-9]{5}\.mccd.*?(?=Script file is closed.)&quot;, log_matrix, re.DOTALL)</code></pre></div>

<div><pre><code class="language-python"># not all hits are indexed by precognition
print(&quot;Indexed %d out of %d hits&quot; %(len(index_info), len(hit_names)))</code></pre></div>

<div><pre><code class="language-none">Indexed 757 out of 825 hits</code></pre></div>

<div><pre><code class="language-python"># we are interested in the missetting matrix data
# From preconition manual version 5.0 section 11.1.1.6
&quot;&quot;&quot;
Missetting matrix defines the rotation from an aligned crystal orientation to any other orientation. 
The aligned crystal orientation is defined as the following: a-b plane is normal to X-ray beam,
that is, a × b or c* is along X-ray beam or Z-axis. a is horizontal to the
right when looking along the X-ray beam, that is, X-axis.

Matrix r11 r12 r13 r21 r22 r23 r31 r32 r33

 = [ r11 r12 r12
     r21 r22 r23
     r31 r32 r33]
     
&quot;&quot;&quot;
print index_info[0] # note, I used these parameters to make a geom file and a cell file for crystfel</code></pre></div>

<div><pre><code class="language-none">@run0001_00149.mccd.inp
Script file &quot;run0001_00149.mccd.inp&quot; is opened for input.
Input
   Crystal    68.300 68.300 108.340 90.000 90.000 90.000 96
Loading the Space-group Database ... The space-group #96 is loaded.
File /usr/local/rri/cpl/ccl/lib/symlib read.
   Matrix     0.419126 -0.690406 -0.589638 0.479264 0.719818 -0.502163 0.771128 -0.072123 0.632582
   Omega      -90.000 0.000
   Goniometer 0.000 0.000 0.000

   Format     RayonixMX340
   Distance   299.949 0.020
   Center     1988.55 1966.88 0.20 0.20
   Pixel      0.088598 0.088600 0.000010 0.000000
   Swing      0.000 0.000 0.000 0.000
   Tilt       -0.016709 -0.231958 0.100000 0.100000
   Bulge      0.000000000000 0.000000000000 0.000000000000 0.000000000000

   Image 0    run0001_00149.mccd
   Resolution 2.20 100.00
   Wavelength 1.02 1.16
   Quit</code></pre></div>

<div><pre><code class="language-python">matrices = []
names = []
for info in index_info:
    lines = info.split(&quot;\n&quot;)
    matrix_info =  map( float, lines[6].split()[1:] )
    name = lines[0].split(&quot;@&quot;)[1].split(&quot;.inp&quot;)[0]
    matrices.append( matrix_info)
    names.append( name)
    </code></pre></div>

<div><pre><code class="language-python">data ={&#39;matrix&#39;:matrices,&#39;name&#39;:names}
df = pandas.DataFrame( data) 
df.to_pickle(&quot;matrix.pkl&quot;)</code></pre></div>

<div><pre><code class="language-python"># we only have integrated intensity values currently for the hits from run 1
ii_names = glob.glob( &quot;integrated_intens/*.ii&quot;)</code></pre></div>

<div><pre><code class="language-python"># not all of the hits with integrated intensity values had orientation matrices in the logs:
ii_names_in_log = [ name for name in ii_names if os.path.basename(name).split(&quot;.ii&quot;)[0] in df.name.values]
print(&quot;%d / %d integrated intensity files had orientation matrix data in the logs&quot;
          %(len(ii_names_in_log), len(ii_names)))</code></pre></div>

<div><pre><code class="language-none">147 / 173 integrated intensity files had orientation matrix data in the logs</code></pre></div>

<div><pre><code class="language-python"># lets load the integrated intensity data in a long-format dataframe

# content of the .ii files is found in the precognution manual v 5.0, section 11.5.6

# note I had to determine which peak coor was pix_fs, pix_ss through trial and error!

all_ii_dfs = []
ii_cols = [&#39;h&#39;,&#39;k&#39;,&#39;l&#39;,&#39;multiplicity&#39;,&#39;pix_fs&#39;,&#39;pix_ss&#39;,&#39;res&#39;,&#39;wavelength&#39;,&#39;Intensity&#39;,&#39;sigma(I)&#39;]
for i_name, name in enumerate(ii_names_in_log):
    ii_data = np.loadtxt(name)
    ii_df = pandas.DataFrame(columns=ii_cols, data=ii_data)
    ii_df[&#39;name&#39;] = os.path.basename(name).split(&#39;.ii&#39;)[0]
    all_ii_dfs.append( ii_df)
    print &quot;\rLoading dataframe %d / %d&quot;%(i_name+1, len( ii_names_in_log)),
    sys.stdout.flush()</code></pre></div>

<div><pre><code class="language-none">Loading dataframe 147 / 147                                                                                                                                                </code></pre></div>

<div><pre><code class="language-python"># store as a dataframe
df_ii = pandas.concat(all_ii_dfs)
df_ii.to_pickle(&quot;integrated_intensity.pkl&quot;)</code></pre></div>

<div><pre><code class="language-python"># now we have to download the files from saguaro!
</code></pre></div>

<p><a name="verify"></a></p>

<h3 id="toc_3">Verify data in the logs</h3>

<div><pre><code class="language-python">%matplotlib inline

import os
import pandas
from IPython.display import clear_output
import h5py
import numpy as np
import pylab as plt
df = pandas.read_pickle(&quot;matrix.pkl&quot;)
df_ii = pandas.read_pickle(&quot;integrated_intensity.pkl&quot;)
</code></pre></div>

<div><pre><code class="language-python">fnames = df_ii.name.unique()
gb = df_ii.groupby(&quot;name&quot;)</code></pre></div>

<div><pre><code class="language-python"># this hdf5 has the image data but binned by a factor of 4!
h5 = h5py.File(&quot;these_images_binned4x.h5&quot;, &quot;r+&quot;)

# therefore we should update the df_ii dataframe to include peak positions binned by same factor
df_ii[&#39;pix_fs_4&#39;] = df_ii.pix_fs/4.
df_ii[&#39;pix_ss_4&#39;] = df_ii.pix_ss/4.</code></pre></div>

<div><pre><code class="language-python">def get_img( fname):
    idx = list(h5[&#39;names&#39;].value).index(fname)
   
    img = h5[&#39;data&#39;][idx]
    return img</code></pre></div>

<div><pre><code class="language-python">f0 = df_ii.name.unique()[0]
ii_0 = gb.get_group( f0) 
img_0 = get_img( f0)</code></pre></div>

<div><pre><code class="language-python">plt.figure(1, figsize=(12,12))
plt.imshow( img_0, vmin=100, vmax=300)</code></pre></div>

<div><pre><code class="language-none">&lt;matplotlib.image.AxesImage at 0x11b71a610&gt;</code></pre></div>

<p><img src="3.png" alt="png"></p>

<div><pre><code class="language-python"># it would be instructive to verify the peaks in our database match up to this image
y,x = ii_0.pix_ss_4, ii_0.pix_fs_4
plt.figure(1, figsize=(12,12))
plt.title(&quot;With peaks!&quot;)
plt.imshow( img_0, vmin=120, vmax=300)
plt.scatter( x, y, s=20, facecolor=&#39;none&#39;, edgecolor=&#39;r&#39;)
</code></pre></div>

<div><pre><code class="language-none">&lt;matplotlib.collections.PathCollection at 0x11c1997d0&gt;</code></pre></div>

<p><img src="4.png" alt="png"></p>

<div><pre><code class="language-python"># Precognition assigns a wavelength to each found Bragg peak..
# ... so lets see what the wavelength distribution from this processed data looks like

df_ii.wavelength.hist(bins=100)
plt.xlabel(&quot;wavelength (Angstrom)&quot;)
plt.ylabel(&quot;bincount&quot;)</code></pre></div>

<div><pre><code class="language-none">Text(0,0.5,&#39;bincount&#39;)</code></pre></div>

<p><img src="5.png" alt="png"></p>

<div><pre><code class="language-python"># It would be interesting to view on our image what the wavelength distribution looks like
plt.figure(1, figsize=(10,8))
plt.scatter( x,y, c=ii_0.wavelength, cmap=&#39;jet_r&#39;, s=20)
plt.colorbar().ax.set_ylabel(&quot;wavelength (Angstrom)&quot;, rotation=270, labelpad=20, fontsize=16)</code></pre></div>

<div><pre><code class="language-none">Text(0,0.5,&#39;wavelength (Angstrom)&#39;)</code></pre></div>

<p><img src="6.png" alt="png"></p>

<div><pre><code class="language-python"># the goal of this analysis is to build a model network that
# can auto-label Bragg peaks in an image like above , given a wavelength spectrum and 
# a found peaks list 
# and perhaps other data, e.g. crystal symmetry information, pixels size.. etc

# once the peaks are labeled according to wavelength, then mosflm can be used to index the image
# (e.g. by picking the largest set of peaks corresponding to a single wavelength)

# The challenge will be to featurize all the above information into an appropriate training set</code></pre></div>

<div><pre><code class="language-python"># Lets try to plot the above with the intensity information as well
plt.figure(1, figsize=(16,13))
plt.imshow( img_0, vmin=50, vmax=350, cmap=&#39;gray&#39;)
plt.scatter( x,y, c=ii_0.wavelength, cmap=&#39;jet_r&#39;, s=40, alpha=0.2) 
plt.colorbar().ax.set_ylabel(&quot;wavelength (Angstrom)&quot;, rotation=270, labelpad=20, fontsize=16)
plt.ylim(960,0)
plt.xlim(0,960)</code></pre></div>

<div><pre><code class="language-none">(0, 960)</code></pre></div>

<p><img src="0.png" alt="png"></p>

<div><pre><code class="language-python"># Actually, based on the above plot, it seems the visible peaks mostly arise
# due to the maximum wavelength in the spectrum

# we can maybe use this information to simplify our model...
</code></pre></div>

<div><pre><code class="language-python"># Before going hard in the paint and setting up this model, 
# lets first verify the main hypothesis
&quot;&quot;&quot;
If we use just isolate central-wavelength Bragg reflections on an image,
then we can use mosflm and &quot;just those peaks&quot; to index the pattern
&quot;&quot;&quot;
# To do test this, we can determine precisely which peaks are central-wavelength peaks

# From the wavelength spectrum above it seems central wavelength is a little greater than 1.03 Angstrom

# Therefore, we will say 1.0275 Angstrom &lt; wavelength &lt; 1.04 Angstrom 
# corresponds to the central wavelength
bins = np.linspace( 1.02, 1.16, 100)
df_ii.wavelength.hist(bins=bins)
df_ii_central = df_ii.query(&quot; %.4f &lt; wavelength &lt; %.4f&quot;%(1.0275, 1.04))
df_ii_central.wavelength.hist(bins=bins)
plt.legend([&quot;all peaks&quot;, &quot;central wavelength peaks&quot;])
plt.ylabel(&quot;bincount&quot;)
plt.xlabel(&quot;wavelength (Angstrom)&quot;)</code></pre></div>

<div><pre><code class="language-none">Text(0.5,0,&#39;wavelength (Angstrom)&#39;)</code></pre></div>

<p><img src="1.png" alt="png"></p>

<div><pre><code class="language-python"># lets pick out just those central wavelength peaks
# and store them in a CXIDB peaks format
# so that we can try to index the patterns using them


# lets make a function to help us out:
def get_peak_from_ii_dataframe(df, h5=h5):
    &quot;&quot;&quot;
    gets peaks positions and intensities (in form of three lists)
    from the integrated intensity dataframes
    
    df is a pandas Integrated intensity dataframe
    h5 is the CXIDB file handle which contains the images described in by df
    
    NOTE: names path in the h5 should correspond to the name column in the df
    &quot;&quot;&quot;
    gb = df.groupby(&quot;name&quot;)
    
    all_y, all_x, all_I = [],[],[]
    name_in_h5_order = h5[&#39;names&#39;].value
    for name in name_in_h5_order:

        #get the peaks only labeled by central wavelength
        df_name = gb.get_group(name)
        y,x = df_name.pix_ss_4 , df_name.pix_fs_4
        I = df_name.Intensity
        all_y.append(y)
        all_x.append(x)
        all_I.append( df_name.Intensity)

    return all_x, all_y, all_I


    </code></pre></div>

<div><pre><code class="language-python">all_x, all_y, all_I = get_peak_from_ii_dataframe( df_ii)
central_x, central_y, central_I = get_peak_from_ii_dataframe(df_ii_central)</code></pre></div>

<div><pre><code class="language-python"># here is a function for updating an already opened h5 file with CXIDB peaks!
def write_cxi_peaks( h5, peaks_path, pkX, pkY, pkI):
    if peaks_path in h5.keys():
        print(&quot;Peaks path &#39;%s&#39; is already taken!&quot;%peaks_path)
        return
    npeaks = np.array( [len(x) for x in pkX] )
    max_n = max(npeaks)
    Nimg = len( pkX )
    
    data_x = np.zeros((Nimg, max_n), dtype=np.float32)
    data_y = np.zeros_like(data_x)
    data_I = np.zeros_like(data_x)

    for i in xrange( Nimg): 
        n = npeaks[i]
        data_x[i,:n] = pkX[i]
        data_y[i,:n] = pkY[i]
        data_I[i,:n] = pkI[i]
    
    peaks = h5.create_group(peaks_path)
    peaks.create_dataset( &#39;nPeaks&#39; , data=npeaks)
    peaks.create_dataset( &#39;peakXPosRaw&#39;, data=data_x )
    peaks.create_dataset( &#39;peakYPosRaw&#39;, data=data_y )
    peaks.create_dataset( &#39;peakTotalIntensity&#39;, data=data_I ) 

</code></pre></div>

<div><pre><code class="language-python">write_cxi_peaks(h5, &quot;all_peaks&quot;, all_x, all_y, all_I)
write_cxi_peaks(h5, &quot;only_central_peaks&quot;, central_x, central_y, central_I)</code></pre></div>

<div><pre><code class="language-none">Peaks path &#39;all_peaks&#39; is already taken!
Peaks path &#39;only_central_peaks&#39; is already taken!</code></pre></div>

<div><pre><code class="language-python"># we can verify these peaks were added to the CXIDB file 
# by using the light-weight ddview (or else your own viewer!)</code></pre></div>

<div><pre><code class="language-python"># lets also look at the intensity of central wavelength peaks vs all the peaks
bins = np.logspace(1,4.4,100)
df_ii.Intensity.hist(bins=bins, log=True)
df_ii_central.Intensity.hist(bins=bins, log=True)
plt.gca().set_xscale(&quot;log&quot;)
plt.ylabel(&quot;bincount&quot;)
plt.xlabel(&quot;Intensity&quot;)
plt.legend([&quot;all peaks&quot;, &quot;central wavelength peaks&quot;])</code></pre></div>

<div><pre><code class="language-none">&lt;matplotlib.legend.Legend at 0x122012910&gt;</code></pre></div>

<p><img src="2.png" alt="png"></p>

<div><pre><code class="language-python"># lets also save just the brightest peaks
df_bright = df_ii.query(&quot;Intensity &gt; 200&quot;)
bright_x, bright_y, bright_I = get_peak_from_ii_dataframe( df_bright)
write_cxi_peaks(h5, &quot;bright_peaks&quot;, bright_x, bright_y, bright_I)

df_brightest = df_ii.query(&quot;Intensity &gt; 400&quot;)
bright_x, bright_y, bright_I = get_peak_from_ii_dataframe( df_brightest)
write_cxi_peaks(h5, &quot;brightest_peaks&quot;, bright_x, bright_y, bright_I)

</code></pre></div>

<div><pre><code class="language-python"># in any case, we will run indexamajig and see how 
# mosflm behaves when using the central wavelength peaks vs all the peaks vs the brightest peaks!</code></pre></div>

<div><pre><code class="language-python">
h5.close()</code></pre></div>

<p><a name="indexa"></a></p>

<h2 id="toc_4">Running indexamajig</h2>

<p>Here we discuss running indexamajig on these data. We populated the CXIDB file with several peak lists. In particular. Using all of the peaks to index failed completely (0% indexing rate). Using the bright peaks had decent success (82.3 % indexing rate) and as expected, using the central wavelengths had a near-perfect indexing rate (99.3 %), in support of the hypothesis. </p>

<p>We ran the following three indexamajig commands (using version 7.0)</p>

<div><pre><code class="language-none">indexamajig  -i 4x.txt  -o 4x_using_brightpeaks.stream -g 4x.geom  --hdf5-peaks=/bright_peaks --peaks=cxi --indexing=mosflm -j 3

indexamajig  -i 4x.txt  -o 4x.stream -g 4x.geom  --hdf5-peaks=/only_central_peaks --peaks=cxi --indexing=mosflm -j 3

indexamajig  -i 4x.txt  -o 4x_using_allpeaks.stream -g 4x.geom  --hdf5-peaks=/all_peaks --peaks=cxi --indexing=mosflm -j 3</code></pre></div>

<p>which produced 3 stream files. (links to stream files coming soon)</p>



<script type="text/javascript">
var _self="undefined"!=typeof window?window:"undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?self:{},Prism=function(){var e=/\blang(?:uage)?-(\w+)\b/i,t=0,n=_self.Prism={util:{encode:function(e){return e instanceof a?new a(e.type,n.util.encode(e.content),e.alias):"Array"===n.util.type(e)?e.map(n.util.encode):e.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/\u00a0/g," ")},type:function(e){return Object.prototype.toString.call(e).match(/\[object (\w+)\]/)[1]},objId:function(e){return e.__id||Object.defineProperty(e,"__id",{value:++t}),e.__id},clone:function(e){var t=n.util.type(e);switch(t){case"Object":var a={};for(var r in e)e.hasOwnProperty(r)&&(a[r]=n.util.clone(e[r]));return a;case"Array":return e.map&&e.map(function(e){return n.util.clone(e)})}return e}},languages:{extend:function(e,t){var a=n.util.clone(n.languages[e]);for(var r in t)a[r]=t[r];return a},insertBefore:function(e,t,a,r){r=r||n.languages;var l=r[e];if(2==arguments.length){a=arguments[1];for(var i in a)a.hasOwnProperty(i)&&(l[i]=a[i]);return l}var o={};for(var s in l)if(l.hasOwnProperty(s)){if(s==t)for(var i in a)a.hasOwnProperty(i)&&(o[i]=a[i]);o[s]=l[s]}return n.languages.DFS(n.languages,function(t,n){n===r[e]&&t!=e&&(this[t]=o)}),r[e]=o},DFS:function(e,t,a,r){r=r||{};for(var l in e)e.hasOwnProperty(l)&&(t.call(e,l,e[l],a||l),"Object"!==n.util.type(e[l])||r[n.util.objId(e[l])]?"Array"!==n.util.type(e[l])||r[n.util.objId(e[l])]||(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,l,r)):(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,null,r)))}},plugins:{},highlightAll:function(e,t){var a={callback:t,selector:'code[class*="language-"], [class*="language-"] code, code[class*="lang-"], [class*="lang-"] code'};n.hooks.run("before-highlightall",a);for(var r,l=a.elements||document.querySelectorAll(a.selector),i=0;r=l[i++];)n.highlightElement(r,e===!0,a.callback)},highlightElement:function(t,a,r){for(var l,i,o=t;o&&!e.test(o.className);)o=o.parentNode;o&&(l=(o.className.match(e)||[,""])[1],i=n.languages[l]),t.className=t.className.replace(e,"").replace(/\s+/g," ")+" language-"+l,o=t.parentNode,/pre/i.test(o.nodeName)&&(o.className=o.className.replace(e,"").replace(/\s+/g," ")+" language-"+l);var s=t.textContent,u={element:t,language:l,grammar:i,code:s};if(!s||!i)return n.hooks.run("complete",u),void 0;if(n.hooks.run("before-highlight",u),a&&_self.Worker){var c=new Worker(n.filename);c.onmessage=function(e){u.highlightedCode=e.data,n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(u.element),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},c.postMessage(JSON.stringify({language:u.language,code:u.code,immediateClose:!0}))}else u.highlightedCode=n.highlight(u.code,u.grammar,u.language),n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(t),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},highlight:function(e,t,r){var l=n.tokenize(e,t);return a.stringify(n.util.encode(l),r)},tokenize:function(e,t){var a=n.Token,r=[e],l=t.rest;if(l){for(var i in l)t[i]=l[i];delete t.rest}e:for(var i in t)if(t.hasOwnProperty(i)&&t[i]){var o=t[i];o="Array"===n.util.type(o)?o:[o];for(var s=0;s<o.length;++s){var u=o[s],c=u.inside,g=!!u.lookbehind,h=!!u.greedy,f=0,d=u.alias;u=u.pattern||u;for(var p=0;p<r.length;p++){var m=r[p];if(r.length>e.length)break e;if(!(m instanceof a)){u.lastIndex=0;var y=u.exec(m),v=1;if(!y&&h&&p!=r.length-1){var b=r[p+1].matchedStr||r[p+1],k=m+b;if(p<r.length-2&&(k+=r[p+2].matchedStr||r[p+2]),u.lastIndex=0,y=u.exec(k),!y)continue;var w=y.index+(g?y[1].length:0);if(w>=m.length)continue;var _=y.index+y[0].length,P=m.length+b.length;if(v=3,P>=_){if(r[p+1].greedy)continue;v=2,k=k.slice(0,P)}m=k}if(y){g&&(f=y[1].length);var w=y.index+f,y=y[0].slice(f),_=w+y.length,S=m.slice(0,w),O=m.slice(_),j=[p,v];S&&j.push(S);var A=new a(i,c?n.tokenize(y,c):y,d,y,h);j.push(A),O&&j.push(O),Array.prototype.splice.apply(r,j)}}}}}return r},hooks:{all:{},add:function(e,t){var a=n.hooks.all;a[e]=a[e]||[],a[e].push(t)},run:function(e,t){var a=n.hooks.all[e];if(a&&a.length)for(var r,l=0;r=a[l++];)r(t)}}},a=n.Token=function(e,t,n,a,r){this.type=e,this.content=t,this.alias=n,this.matchedStr=a||null,this.greedy=!!r};if(a.stringify=function(e,t,r){if("string"==typeof e)return e;if("Array"===n.util.type(e))return e.map(function(n){return a.stringify(n,t,e)}).join("");var l={type:e.type,content:a.stringify(e.content,t,r),tag:"span",classes:["token",e.type],attributes:{},language:t,parent:r};if("comment"==l.type&&(l.attributes.spellcheck="true"),e.alias){var i="Array"===n.util.type(e.alias)?e.alias:[e.alias];Array.prototype.push.apply(l.classes,i)}n.hooks.run("wrap",l);var o="";for(var s in l.attributes)o+=(o?" ":"")+s+'="'+(l.attributes[s]||"")+'"';return"<"+l.tag+' class="'+l.classes.join(" ")+'" '+o+">"+l.content+"</"+l.tag+">"},!_self.document)return _self.addEventListener?(_self.addEventListener("message",function(e){var t=JSON.parse(e.data),a=t.language,r=t.code,l=t.immediateClose;_self.postMessage(n.highlight(r,n.languages[a],a)),l&&_self.close()},!1),_self.Prism):_self.Prism;var r=document.currentScript||[].slice.call(document.getElementsByTagName("script")).pop();return r&&(n.filename=r.src,document.addEventListener&&!r.hasAttribute("data-manual")&&document.addEventListener("DOMContentLoaded",n.highlightAll)),_self.Prism}();"undefined"!=typeof module&&module.exports&&(module.exports=Prism),"undefined"!=typeof global&&(global.Prism=Prism);
</script>

<script type="text/javascript">
Prism.languages.python={"triple-quoted-string":{pattern:/"""[\s\S]+?"""|'''[\s\S]+?'''/,alias:"string"},comment:{pattern:/(^|[^\\])#.*/,lookbehind:!0},string:/("|')(?:\\?.)*?\1/,"function":{pattern:/((?:^|\s)def[ \t]+)[a-zA-Z_][a-zA-Z0-9_]*(?=\()/g,lookbehind:!0},"class-name":{pattern:/(\bclass\s+)[a-z0-9_]+/i,lookbehind:!0},keyword:/\b(?:as|assert|async|await|break|class|continue|def|del|elif|else|except|exec|finally|for|from|global|if|import|in|is|lambda|pass|print|raise|return|try|while|with|yield)\b/,"boolean":/\b(?:True|False)\b/,number:/\b-?(?:0[bo])?(?:(?:\d|0x[\da-f])[\da-f]*\.?\d*|\.\d+)(?:e[+-]?\d+)?j?\b/i,operator:/[-+%=]=?|!=|\*\*?=?|\/\/?=?|<[<=>]?|>[=>]?|[&|^~]|\b(?:or|and|not)\b/,punctuation:/[{}[\];(),.:]/};
</script>

<script type="text/x-mathjax-config">
(function () {

MathJax.Hub.Config({
	'showProcessingMessages': false,
	'messageStyle': 'none'
});

if (typeof MathJaxListener !== 'undefined') {
	MathJax.Hub.Register.StartupHook('End', function () {
		MathJaxListener.invokeCallbackForKey_('End');
	});
}

})();
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


</body>

</html>
